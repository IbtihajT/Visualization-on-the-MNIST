{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff6e370fa10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a random Image\n",
    "plt.imshow(train_images[56], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before reshaping: (60000, 28, 28)\n",
      "Shape after reshaping: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make Rank-4 Tensors as cast the dtype to 'float32'\n",
    "print(f\"Shape before reshaping: {train_images.shape}\")\n",
    "train_images = train_images.reshape(\n",
    "    train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_images = test_images.reshape(\n",
    "    test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "print(f\"Shape after reshaping: {train_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape before: (60000,)\n",
      "Labels shape after one-hot: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to one-hot vectors\n",
    "print(f\"Labels shape before: {train_labels.shape}\")\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print(f\"Labels shape after one-hot: {train_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:24:27.577635Z",
     "start_time": "2019-09-08T13:24:27.566574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define CNN Architecture\n",
    "def baseline_Model(input_shape):\n",
    "\n",
    "    # Get Sequential Model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Convolutional Block\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
    "                     activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5),\n",
    "                     padding='Same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 2nd Convolutional Block\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     padding='Same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                     padding='Same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Classification Block\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    # Compile the Model\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Set a learning rate annealer\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                                patience=3,\n",
    "                                                verbose=1,\n",
    "                                                factor=0.5,\n",
    "                                                min_lr=0.00001)\n",
    "    return model, learning_rate_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:24:28.112967Z",
     "start_time": "2019-09-08T13:24:27.603413Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Metadata\n",
    "input_shape = train_images.shape[1:]\n",
    "epochs = 30\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model and learning_rate_reduction\n",
    "model, learning_rate_reduction = baseline_Model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# See the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:28:39.794556Z",
     "start_time": "2019-09-08T13:24:28.137614Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59942/60000 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9509WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59942/60000 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9509 - val_loss: 0.0440 - val_accuracy: 0.9857Epoch 2/30\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9841WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9841 - val_loss: 0.0268 - val_accuracy: 0.9912Epoch 3/30\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9876WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.0206 - val_accuracy: 0.9935Epoch 4/30\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9897WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9897 - val_loss: 0.0270 - val_accuracy: 0.9907Epoch 5/30\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9912WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0191 - val_accuracy: 0.9941Epoch 6/30\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9918WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.0180 - val_accuracy: 0.9938Epoch 7/30\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9922WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.0168 - val_accuracy: 0.9954Epoch 8/30\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9925WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0217 - val_accuracy: 0.9932Epoch 9/30\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9930WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "59914/60000 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.0262 - val_accuracy: 0.9923Epoch 10/30\n",
      "  918/60000 [..............................] - ETA: 3:47 - loss: 0.0219 - accuracy: 0.9940WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-28b3a88b9c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the Model\n",
    "history = model.fit(\n",
    "    x=train_images,\n",
    "    y=train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=True,\n",
    "    callbacks=[learning_rate_reduction],\n",
    "    validation_data=(test_images, test_labels),\n",
    "    steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:28:49.847211Z",
     "start_time": "2019-09-08T13:28:49.321335Z"
    }
   },
   "outputs": [],
   "source": [
    "img_Path = \"5.jpg\"\n",
    "%matplotlib inline\n",
    "\n",
    "img = image.load_img(img_Path, color_mode='grayscale', target_size=(28, 28))\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "img_Tensor = image.img_to_array(img)\n",
    "img_Tensor = np.expand_dims(img_Tensor, axis=0)\n",
    "\n",
    "img_Tensor /= 255\n",
    "\n",
    "print(img_Tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:29:31.234367Z",
     "start_time": "2019-09-08T13:29:31.222337Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_Outputs = [layer.output for layer in my_Model.layers[:8]]\n",
    "activation = models.Model(inputs=my_Model.input, outputs=layer_Outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:29:31.853753Z",
     "start_time": "2019-09-08T13:29:31.735429Z"
    }
   },
   "outputs": [],
   "source": [
    "activations = activation.predict(img_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:29:32.278577Z",
     "start_time": "2019-09-08T13:29:32.265706Z"
    }
   },
   "outputs": [],
   "source": [
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:29:33.062475Z",
     "start_time": "2019-09-08T13:29:32.939290Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(first_layer_activation[0, :, :, 11], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T13:29:39.724079Z",
     "start_time": "2019-09-08T13:29:39.130301Z"
    }
   },
   "outputs": [],
   "source": [
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = []\n",
    "for layer in my_Model.layers[:3]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "# Now let's display our feature maps\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    # This is the number of features in the feature map\n",
    "    n_features = layer_activation.shape[-1]\n",
    "\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # We will tile the activation channels in this matrix\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    # We'll tile each filter into this big horizontal grid\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            # Post-process the feature to make it visually palatable\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size: (col + 1) * size,\n",
    "                         row * size: (row + 1) * size] = channel_image\n",
    "\n",
    "    # Display the grid\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "417px",
    "left": "231px",
    "right": "20px",
    "top": "24px",
    "width": "778px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
